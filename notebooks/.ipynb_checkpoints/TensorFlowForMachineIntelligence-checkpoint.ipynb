{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 面向机器智能的TensorFlow实践\n",
    "\n",
    "### 2.8 测试TensorFlow、Jupyter Notebook及matplotlib\n",
    "\n",
    "1. 用TensorFlow定义一个由随机数构成的2X20的矩阵，并将其赋给变量a。\n",
    "2. 启动TensorFlow Session，并将其赋予一个sess对象。\n",
    "3. 用sess.run()方法执行对象a，并将输出（NumPy数组）赋给out。\n",
    "4. 将这个2X20的矩阵划分为两个1X10的向量x和y。\n",
    "5. 利用pyplot模块绘制散点图，x对应横轴，y对应纵轴。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM/8P8L6Eo2sCbAoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c60f5be50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "a = tf.random_normal([2,20])\n",
    "sess = tf.Session()\n",
    "out = sess.run(a)\n",
    "x, y = out\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 构建第一个TensorFlow数据流图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(5, name=\"input_a\")\n",
    "b = tf.constant(3, name=\"input_b\")\n",
    "c = tf.multiply(a, b, name=\"mul_c\")\n",
    "d = tf.add(a, b, name=\"add_d\")\n",
    "e = tf.add(c, d, name=\"add_e\")\n",
    "\n",
    "sess = tf.Session()\n",
    "output = sess.run(e)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 运算符重载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(5, name=\"input_a\")\n",
    "b = tf.constant(3, name=\"input_b\")\n",
    "c = a * b\n",
    "d = a + b\n",
    "e = c + d\n",
    "\n",
    "sess = tf.Session()\n",
    "output = sess.run(e)\n",
    "\n",
    "sess.close()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.2.5 TensorFlow中的Graph对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # 像往常一样创建一些Op；它们将被添加到Graph对象g中\n",
    "    a = tf.multiply(2, 3)\n",
    "\n",
    "# 由于不在with语句块中，下面的Op将放置在默认数据流图中\n",
    "also_in_default_graph = tf.subtract(5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.7 利用占位符点添加输入\n",
    "\n",
    "占位符的行为与Tensor对象一致，但在创建时无须为它们指定具体的数值。它们的作用是为运行时即将到来的某个Tensor对象预留位置，因此实际上变成了“输入”节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个长度为2、数据类型为int32的占位向量\n",
    "a = tf.placeholder(tf.int32, shape=[2], name=\"my_input\")\n",
    "\n",
    "# 将该占位向量视为其他任意Tensor对象，加以使用\n",
    "b = tf.reduce_prod(a, name=\"prod_b\")\n",
    "c = tf.reduce_sum(a, name=\"prod_c\")\n",
    "\n",
    "d = tf.add(b, c, name=\"add_d\")\n",
    "\n",
    "# 定义一个TensorFlow Session对象\n",
    "sess = tf.Session()\n",
    "\n",
    "# 创建一个将传给feed_dict参数的字典\n",
    "# 键：'a'，指向占位符输出Tensor对象的句柄\n",
    "# 值：一个值为[5,3]、类型为int32的向量\n",
    "input_dict = {a: np.array([5,3], dtype=np.int32)}\n",
    "\n",
    "# 计算d的值，将input_dict的“值”传给a\n",
    "sess.run(d, feed_dict=input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.8 Variable对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 为Variable对象传入一个初始值3\n",
    "my_var = tf.Variable(3, name=\"my_variable\")\n",
    "\n",
    "add = tf.add(5, my_var)\n",
    "mul = tf.multiply(8, my_var)\n",
    "\n",
    "sess = tf.Session()\n",
    "print( sess.run(add, {my_var: 3}) )\n",
    "print( sess.run(mul, {my_var: 3}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 为Variable对象传入一个初始值3\n",
    "my_var = tf.Variable(3, name=\"my_variable\")\n",
    "\n",
    "add = tf.add(5, my_var)\n",
    "mul = tf.multiply(8, my_var)\n",
    "\n",
    "# init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print( sess.run(add) )\n",
    "print( sess.run(mul) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "[ 1.  1.  1.  1.  1.  1.]\n",
      "[[[ 8.15243721  9.32383537  5.28775692]\n",
      "  [ 8.42719269  9.83672714  1.32969856]\n",
      "  [ 0.14772892  4.36676264  9.90128422]]\n",
      "\n",
      " [[ 6.84358358  2.77854204  5.9880867 ]\n",
      "  [ 9.18852329  7.1083107   5.60181046]\n",
      "  [ 7.83084488  3.31484318  7.82800579]]\n",
      "\n",
      " [[ 9.49655628  6.06481171  2.36369491]\n",
      "  [ 6.45089149  6.4335227   3.72446537]\n",
      "  [ 4.1134367   3.40673685  2.61717081]]]\n",
      "[[[-1.16931629 -2.68397355 -1.72735262]\n",
      "  [ 0.25375244 -0.48912179 -0.73237044]\n",
      "  [-0.14452195 -2.37195325  3.06649232]]\n",
      "\n",
      " [[-1.83400011 -0.4650743  -1.68667555]\n",
      "  [ 1.75957501  1.67953122 -0.12990482]\n",
      "  [ 2.65452886  2.40396762  3.45351481]]\n",
      "\n",
      " [[-1.26838553 -0.6958999   0.24704079]\n",
      "  [-1.3884877  -0.22733845  0.21446256]\n",
      "  [ 0.92495477  0.59236133 -0.06153692]]]\n",
      "[[[ 5.52929974  4.37307405  4.78891802]\n",
      "  [ 4.74285269  6.93629265  4.53819609]\n",
      "  [ 4.52012014  4.55895758  3.7787745 ]]\n",
      "\n",
      " [[ 5.86922026  4.93699646  3.39458871]\n",
      "  [ 6.13938713  6.62521267  6.0493145 ]\n",
      "  [ 5.62196541  3.9776628   5.38107538]]\n",
      "\n",
      " [[ 4.64971924  4.7945714   6.23667336]\n",
      "  [ 3.98779488  4.00457382  3.40785742]\n",
      "  [ 6.07830048  6.71984291  4.83924913]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 2x2的零矩阵\n",
    "zeros = tf.zeros([2, 2])\n",
    "\n",
    "# 长度为6的全1向量\n",
    "ones = tf.ones([6])\n",
    "\n",
    "# 3x3x3的张量，其元素服从0~10的均匀分布\n",
    "uniform = tf.random_uniform([3, 3, 3], minval=0, maxval=10)\n",
    "\n",
    "# 3x3x3的张量，其元素服从0均值、标准差为2的正态分布\n",
    "normal = tf.random_normal([3, 3, 3], mean=0.0, stddev=2.0)\n",
    "\n",
    "# 3x3x3的张量，其元素服从任何偏离均值不会超过2倍标准差的值，从而可以防止有一个或两个元素与该张量中的其他元素显著不同的情况出现\n",
    "truncated = tf.truncated_normal([3, 3, 3], mean=5.0, stddev=1.0)\n",
    "\n",
    "sess = tf.Session()\n",
    "out_zeros = sess.run(zeros)\n",
    "out_ones = sess.run(ones)\n",
    "out_uniform = sess.run(uniform)\n",
    "out_normal = sess.run(normal)\n",
    "out_truncated = sess.run(truncated)\n",
    "\n",
    "print( out_zeros )\n",
    "print( out_ones )\n",
    "print( out_uniform )\n",
    "print( out_normal )\n",
    "print( out_truncated )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "var1 = tf.Variable(0, name=\"initialize_me\")\n",
    "var2 = tf.Variable(1, name=\"no_initialization\")\n",
    "\n",
    "#init = tf.initialize_variables([var1], \"init_var1\")\n",
    "init = tf.variables_initializer([var1], \"init_var1\")\n",
    "\n",
    "sess = tf.Session()\n",
    "out = sess.run(init)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 创建一个初值为1的Variable对象\n",
    "my_var = tf.Variable(1)\n",
    "\n",
    "# 创建一个Op，使其在每次运行时都将该Variable对象乘以2\n",
    "my_var_times_two = my_var.assign(my_var * 2)\n",
    "\n",
    "# 初始化Op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# 初始化Variable对象\n",
    "sess.run(init)\n",
    "\n",
    "# 将Variable对象乘以2，并将其返回\n",
    "out1 = sess.run(my_var_times_two)\n",
    "print(out1)\n",
    "# 输出：2\n",
    "\n",
    "# 将Variable对象乘以2，并将其返回\n",
    "out2 = sess.run(my_var_times_two)\n",
    "print(out2)\n",
    "# 输出：4\n",
    "\n",
    "# 将Variable对象乘以2，并将其返回\n",
    "out3 = sess.run(my_var_times_two)\n",
    "print(out3)\n",
    "# 输出：8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "my_var = tf.Variable(1)\n",
    "out1 = my_var.assign_add(5)\n",
    "out2 = my_var.assign_sub(2)\n",
    "\n",
    "# 初始化Op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print( sess.run(out1) )\n",
    "## 6\n",
    "print( sess.run(out2) )\n",
    "## 4\n",
    "\n",
    "# 如果希望将所有Variable对象的值重置为初始值，则只需要再次调用global_variables_initializer，也就是运行sess.run(init)\n",
    "sess.run(init)\n",
    "print( sess.run(out2) )\n",
    "## -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 通过名称作用域组织数据流图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    in_1 = tf.placeholder(tf.float32, shape=[], name=\"input_a\")\n",
    "    in_2 = tf.placeholder(tf.float32, shape=[], name=\"input_b\")\n",
    "    const = tf.constant(3, dtype=tf.float32, name=\"static_value\")\n",
    "    \n",
    "    with tf.name_scope(\"Transformation\"):\n",
    "        \n",
    "        with tf.name_scope(\"A\"):\n",
    "            A_mul = tf.multiply(in_1, const)\n",
    "            A_out = tf.subtract(A_mul, in_1)\n",
    "            \n",
    "        with tf.name_scope(\"B\"):\n",
    "            B_mul = tf.multiply(in_2, const)\n",
    "            B_out = tf.subtract(B_mul, in_2)\n",
    "            \n",
    "        with tf.name_scope(\"C\"):\n",
    "            C_div = tf.div(A_out, B_out)\n",
    "            C_out = tf.add(C_div, const)\n",
    "            \n",
    "        with tf.name_scope(\"C\"):\n",
    "            D_div = tf.div(B_out, A_out)\n",
    "            D_out = tf.add(D_div, const)\n",
    "            \n",
    "writer = tf.summary.FileWriter('../logs', graph=graph)\n",
    "print(\"ok\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope(\"variables\"):\n",
    "        # 记录数据流图运行次数的Variable对象\n",
    "        global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\"global_step\")\n",
    "        \n",
    "        # 追踪该模型的所有输出随时间的累加和的Variable对象\n",
    "        total_output = tf.Variable(0.0, dtype=tf.float32, trainable=False, name=\"total_output\")\n",
    "    with tf.name_scope(\"transformation\"):\n",
    "        with tf.name_scope(\"input\"):\n",
    "            # 创建输出占位符，用于接收一个向量\n",
    "            a = tf.placeholder(tf.float32, shape=[None], name=\"input_placeholder_a\")\n",
    "        \n",
    "        with tf.name_scope(\"intermediate_layer\"):\n",
    "            b = tf.reduce_prod(a, name=\"product_b\")\n",
    "            c = tf.reduce_sum(a, name=\"sum_c\")\n",
    "            \n",
    "        # 独立的输出层\n",
    "        with tf.name_scope(\"output\"):\n",
    "            output = tf.add(b, c, name=\"output\")\n",
    "    with tf.name_scope(\"update\"):\n",
    "        # 用最新的输出更新Variable对象total_output\n",
    "        update_total = total_output.assign_add(output)\n",
    "        # 将前面的Variable对象global_step增1，只要数据流图运行，该操作便需要运行\n",
    "        increment_step = global_step.assign_add(1)\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        avg = tf.div(update_total, tf.cast(increment_step, tf.float32), name=\"average\")\n",
    "        \n",
    "        # 为输出节点创建汇总数据\n",
    "        tf.summary.scalar(b'Output', output)\n",
    "        tf.summary.scalar(b'Sum_of_outputs_over_time', update_total)\n",
    "        tf.summary.scalar(b'Average_of_outputs_over_time', avg)\n",
    "    with tf.name_scope(\"global_ops\"):\n",
    "        # 初始化Op\n",
    "        init = tf.global_variables_initializer()\n",
    "        # 将所有汇总数据合并到一个Op中\n",
    "        merged_summaries = tf.summary.merge_all()\n",
    "# 用明确创建的Graph对象启动一个会话\n",
    "sess = tf.Session(graph=graph)\n",
    "# 开启一个Summary.FileWriter对象，保存汇总数据\n",
    "writer = tf.summary.FileWriter('../logs', graph=graph)\n",
    "# 初始化Variable对象\n",
    "sess.run(init)\n",
    "\n",
    "def run_graph(input_tensor):\n",
    "    \"\"\"\n",
    "    辅助函数；用给定的输入张量运行数据流图，并保存汇总数据\n",
    "    \"\"\"\n",
    "    feed_dict = {a: input_tensor}\n",
    "    _, step, summary = sess.run([output, increment_step, merged_summaries], feed_dict=feed_dict)\n",
    "    writer.add_summary(summary, global_step=step)\n",
    "    \n",
    "    \n",
    "# 用不同的输入运行该数据流图\n",
    "run_graph([2, 8])\n",
    "run_graph([3, 1, 3, 3])\n",
    "run_graph([8])\n",
    "run_graph([1, 2, 3])\n",
    "run_graph([11, 4])\n",
    "run_graph([4, 1])\n",
    "run_graph([7, 3, 1])\n",
    "run_graph([6, 3])\n",
    "run_graph([0, 2])\n",
    "run_graph([4, 5, 6])\n",
    "\n",
    "# 将汇总数据写入磁盘\n",
    "writer.flush()\n",
    "\n",
    "# 关闭Summary.FileWriter对象\n",
    "writer.close()\n",
    "\n",
    "# 关闭Session对象\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 有监督学习简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-491ec4da01b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 初始化变量和模型参数，定义训练闭环中的运算\n",
    "\n",
    "def inference(X):\n",
    "    # 计算推断模型在数据X上的输出，并将结果返回\n",
    "def loss(X, Y):\n",
    "    # 依据训练数据X及其期望输出Y计算损失\n",
    "def inputs():\n",
    "    # 读取或生成训练数据X及其期望输出Y\n",
    "def train(total_loss):\n",
    "    # 依据计算的总损失训练或调整模型参数\n",
    "def evaluate(sess, X, Y):\n",
    "    # 对训练得到的模型进行评估\n",
    "    \n",
    "# 在一个会话对象中启动数据流图，搭建流程\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X, Y = inputs()\n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 实际的训练迭代次数\n",
    "    training_steps = 1000\n",
    "    for steps in range(training_steps):\n",
    "        sess.run([train_op])\n",
    "        # 出于调试和学习的目的，查看损失在训练过程中递减的情况\n",
    "        if step % 10 == 0:\n",
    "            print \"loss: \", sess.run([total_loss])\n",
    "            \n",
    "    evaluate(sess, X, Y)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  [7608772.5]\n",
      "loss:  [5352849.5]\n",
      "loss:  [5350043.5]\n",
      "loss:  [5347918.5]\n",
      "loss:  [5346299.5]\n",
      "loss:  [5345061.0]\n",
      "loss:  [5344105.5]\n",
      "loss:  [5343361.0]\n",
      "loss:  [5342774.0]\n",
      "loss:  [5342306.0]\n",
      "loss:  [5341925.5]\n",
      "loss:  [5341611.0]\n",
      "loss:  [5341345.0]\n",
      "loss:  [5341115.5]\n",
      "loss:  [5340913.0]\n",
      "loss:  [5340733.0]\n",
      "loss:  [5340566.5]\n",
      "loss:  [5340413.5]\n",
      "loss:  [5340268.0]\n",
      "loss:  [5340128.0]\n",
      "loss:  [5339993.0]\n",
      "loss:  [5339860.5]\n",
      "loss:  [5339733.5]\n",
      "loss:  [5339606.0]\n",
      "loss:  [5339482.5]\n",
      "loss:  [5339357.5]\n",
      "loss:  [5339234.5]\n",
      "loss:  [5339112.0]\n",
      "loss:  [5338989.5]\n",
      "loss:  [5338869.0]\n",
      "loss:  [5338747.0]\n",
      "loss:  [5338624.5]\n",
      "loss:  [5338503.5]\n",
      "loss:  [5338385.0]\n",
      "loss:  [5338262.0]\n",
      "loss:  [5338141.0]\n",
      "loss:  [5338022.5]\n",
      "loss:  [5337900.5]\n",
      "loss:  [5337780.5]\n",
      "loss:  [5337661.0]\n",
      "loss:  [5337538.5]\n",
      "loss:  [5337418.5]\n",
      "loss:  [5337297.0]\n",
      "loss:  [5337177.5]\n",
      "loss:  [5337056.5]\n",
      "loss:  [5336936.5]\n",
      "loss:  [5336815.0]\n",
      "loss:  [5336695.5]\n",
      "loss:  [5336574.5]\n",
      "loss:  [5336455.0]\n",
      "loss:  [5336334.0]\n",
      "loss:  [5336213.0]\n",
      "loss:  [5336092.5]\n",
      "loss:  [5335973.0]\n",
      "loss:  [5335852.5]\n",
      "loss:  [5335732.5]\n",
      "loss:  [5335610.5]\n",
      "loss:  [5335491.5]\n",
      "loss:  [5335370.5]\n",
      "loss:  [5335250.0]\n",
      "loss:  [5335129.5]\n",
      "loss:  [5335009.0]\n",
      "loss:  [5334888.0]\n",
      "loss:  [5334768.5]\n",
      "loss:  [5334647.0]\n",
      "loss:  [5334526.5]\n",
      "loss:  [5334409.0]\n",
      "loss:  [5334287.0]\n",
      "loss:  [5334167.5]\n",
      "loss:  [5334048.0]\n",
      "loss:  [5333925.5]\n",
      "loss:  [5333806.0]\n",
      "loss:  [5333685.5]\n",
      "loss:  [5333565.5]\n",
      "loss:  [5333446.0]\n",
      "loss:  [5333326.0]\n",
      "loss:  [5333205.5]\n",
      "loss:  [5333085.0]\n",
      "loss:  [5332965.0]\n",
      "loss:  [5332844.5]\n",
      "loss:  [5332724.0]\n",
      "loss:  [5332603.5]\n",
      "loss:  [5332485.0]\n",
      "loss:  [5332363.5]\n",
      "loss:  [5332243.5]\n",
      "loss:  [5332123.5]\n",
      "loss:  [5332002.5]\n",
      "loss:  [5331883.5]\n",
      "loss:  [5331762.5]\n",
      "loss:  [5331642.0]\n",
      "loss:  [5331523.0]\n",
      "loss:  [5331403.0]\n",
      "loss:  [5331282.0]\n",
      "loss:  [5331162.0]\n",
      "loss:  [5331042.0]\n",
      "loss:  [5330922.5]\n",
      "loss:  [5330802.5]\n",
      "loss:  [5330682.0]\n",
      "loss:  [5330562.5]\n",
      "loss:  [5330442.5]\n",
      "[[ 320.64968872]]\n",
      "[[ 267.78182983]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# w1, w2, ..., wk为模型从训练数据中学习到的参数，或赋予每个变量的“权值”\n",
    "W = tf.Variable(tf.zeros([2,1]), name=\"weights\")\n",
    "# b也是一个学习到的参数，这个线性代数中的常量也称为模型的偏置（bias）\n",
    "b = tf.Variable(0., name=\"bias\")\n",
    "\n",
    "# 初始化变量和模型参数，定义训练闭环中的运算\n",
    "\n",
    "def inference(X):\n",
    "    # 计算推断模型在数据X上的输出，并将结果返回\n",
    "    return tf.matmul(X, W) + b\n",
    "def loss(X, Y):\n",
    "    # 依据训练数据X及其期望输出Y计算损失\n",
    "    Y_predicted = inference(X)\n",
    "    return tf.reduce_sum(tf.squared_difference(Y, Y_predicted))\n",
    "def inputs():\n",
    "    # 读取或生成训练数据X及其期望输出Y\n",
    "    weight_age = [[84,46],[73,20],[65,52],[70,30],\n",
    "                 [76,57],[69,25],[63,28],[72,36],[79,57],[75,44],\n",
    "                 [27,24],[89,31],[65,52],[57,23],[59,60],[69,48],\n",
    "                 [60,34],[79,51],[75,50],[82,34],[59,46],[67,23],\n",
    "                 [85,37],[55,40],[63,30]]\n",
    "    blood_fat_content = [354,190,405,263,451,302,288,\n",
    "                        385,402,365,209,290,346,254,395,434,220,374,308,\n",
    "                        220,311,181,274,303,244]\n",
    "    return tf.to_float(weight_age), tf.to_float(blood_fat_content)\n",
    "def train(total_loss):\n",
    "    # 依据计算的总损失训练或调整模型参数\n",
    "    learning_rate = 0.0000001\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "def evaluate(sess, X, Y):\n",
    "    # 对训练得到的模型进行评估\n",
    "    print sess.run(inference([[80., 25.]])) # ~303\n",
    "    print sess.run(inference([[65., 25.]])) # ~256\n",
    "    \n",
    "# 在一个会话对象中启动数据流图，搭建流程\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X, Y = inputs()\n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 实际的训练迭代次数\n",
    "    training_steps = 1000\n",
    "    for step in range(training_steps):\n",
    "        sess.run([train_op])\n",
    "        # 出于调试和学习的目的，查看损失在训练过程中递减的情况\n",
    "        if step % 10 == 0:\n",
    "            print \"loss: \", sess.run([total_loss])\n",
    "            \n",
    "    evaluate(sess, X, Y)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
