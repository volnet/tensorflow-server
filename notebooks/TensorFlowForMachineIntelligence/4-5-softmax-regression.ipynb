{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 softmax分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/TensorFlowForMachineIntelligence/data/archive_ics_uci_edu_ml_machine-learning-databases_iris/iris.data\n",
      "loss:  [1.0898101]\n",
      "loss:  [1.0255945]\n",
      "loss:  [0.96274871]\n",
      "loss:  [0.92197585]\n",
      "loss:  [0.87096161]\n",
      "loss:  [0.83135492]\n",
      "loss:  [0.8084774]\n",
      "loss:  [0.74558854]\n",
      "loss:  [0.73596221]\n",
      "loss:  [0.72645903]\n",
      "loss:  [0.71248621]\n",
      "loss:  [0.64435369]\n",
      "loss:  [0.71710223]\n",
      "loss:  [0.67891771]\n",
      "loss:  [0.63535327]\n",
      "loss:  [0.65278]\n",
      "loss:  [0.59815222]\n",
      "loss:  [0.56261504]\n",
      "loss:  [0.60426992]\n",
      "loss:  [0.57958722]\n",
      "loss:  [0.56375986]\n",
      "loss:  [0.57519257]\n",
      "loss:  [0.58381337]\n",
      "loss:  [0.5260874]\n",
      "loss:  [0.59285313]\n",
      "loss:  [0.55544424]\n",
      "loss:  [0.55109018]\n",
      "loss:  [0.56683725]\n",
      "loss:  [0.56172943]\n",
      "loss:  [0.50046748]\n",
      "loss:  [0.54106611]\n",
      "loss:  [0.53424037]\n",
      "loss:  [0.50997531]\n",
      "loss:  [0.56429338]\n",
      "loss:  [0.49851722]\n",
      "loss:  [0.4680905]\n",
      "loss:  [0.48160231]\n",
      "loss:  [0.49164033]\n",
      "loss:  [0.44408408]\n",
      "loss:  [0.51108491]\n",
      "loss:  [0.49914119]\n",
      "loss:  [0.45118889]\n",
      "loss:  [0.51028806]\n",
      "loss:  [0.4669376]\n",
      "loss:  [0.42372391]\n",
      "loss:  [0.48769584]\n",
      "loss:  [0.4779554]\n",
      "loss:  [0.40700623]\n",
      "loss:  [0.45060676]\n",
      "loss:  [0.43932101]\n",
      "loss:  [0.43062064]\n",
      "loss:  [0.42121479]\n",
      "loss:  [0.42437348]\n",
      "loss:  [0.45399034]\n",
      "loss:  [0.43659493]\n",
      "loss:  [0.43276969]\n",
      "loss:  [0.39454204]\n",
      "loss:  [0.42575085]\n",
      "loss:  [0.43649933]\n",
      "loss:  [0.38247386]\n",
      "loss:  [0.43909293]\n",
      "loss:  [0.43591797]\n",
      "loss:  [0.38493904]\n",
      "loss:  [0.45882562]\n",
      "loss:  [0.41741362]\n",
      "loss:  [0.39820695]\n",
      "loss:  [0.41755006]\n",
      "loss:  [0.39841416]\n",
      "loss:  [0.38224483]\n",
      "loss:  [0.4237037]\n",
      "loss:  [0.44179505]\n",
      "loss:  [0.36416036]\n",
      "loss:  [0.42506337]\n",
      "loss:  [0.44444671]\n",
      "loss:  [0.37464827]\n",
      "loss:  [0.38396451]\n",
      "loss:  [0.39361459]\n",
      "loss:  [0.36248261]\n",
      "loss:  [0.36606964]\n",
      "loss:  [0.4203414]\n",
      "loss:  [0.35169998]\n",
      "loss:  [0.39672509]\n",
      "loss:  [0.42518175]\n",
      "loss:  [0.37702134]\n",
      "loss:  [0.39719743]\n",
      "loss:  [0.33620185]\n",
      "loss:  [0.36980641]\n",
      "loss:  [0.39657184]\n",
      "loss:  [0.37667787]\n",
      "loss:  [0.38876054]\n",
      "loss:  [0.38127685]\n",
      "loss:  [0.35874954]\n",
      "loss:  [0.3577871]\n",
      "loss:  [0.40336663]\n",
      "loss:  [0.34896478]\n",
      "loss:  [0.34569588]\n",
      "loss:  [0.39272159]\n",
      "loss:  [0.38776734]\n",
      "loss:  [0.3795453]\n",
      "loss:  [0.35720593]\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# w1, w2, ..., wk为模型从训练数据中学习到的参数，或赋予每个变量的“权值”\n",
    "W = tf.Variable(tf.zeros([4,3]), name=\"weights\")\n",
    "# b也是一个学习到的参数，这个线性代数中的常量也称为模型的偏置（bias）\n",
    "b = tf.Variable(tf.zeros([3]), name=\"bias\")\n",
    "\n",
    "# 初始化变量和模型参数，定义训练闭环中的运算\n",
    "\n",
    "def combine_inputs(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "def inference(X):\n",
    "    # 计算推断模型在数据X上的输出，并将结果返回\n",
    "    return tf.nn.softmax(combine_inputs(X))\n",
    "def loss(X, Y):\n",
    "    # 依据训练数据X及其期望输出Y计算损失\n",
    "    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=combine_inputs(X)))\n",
    "def read_csv(batch_size, file_name, record_defaults):\n",
    "    filepath = os.getcwd() + '/data/archive_ics_uci_edu_ml_machine-learning-databases_iris/' + file_name\n",
    "    print filepath\n",
    "    filename_queue = tf.train.string_input_producer([filepath])\n",
    "    reader = tf.TextLineReader(skip_header_lines=0)\n",
    "    key, value = reader.read(filename_queue)\n",
    "    \n",
    "    # decode_csv会将字符串（文本行）转换到具有制定默认值的由张量列构成的元组中\n",
    "    # 它还会为每一列设置数据类型\n",
    "    decoded = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "    \n",
    "    # 实际上会读取一个文件，并加载一个张量中的batch_size行\n",
    "    return tf.train.shuffle_batch(decoded, batch_size=batch_size, capacity=batch_size*50, min_after_dequeue=batch_size)\n",
    "def inputs():\n",
    "    # 读取或生成训练数据X及其期望输出Y\n",
    "    sepal_length, sepal_width, petal_length, petal_width, label = \\\n",
    "    read_csv(100, \"iris.data\", [[0.0], [0.0], [0.0], [0.0], [\"\"]])\n",
    "    \n",
    "    # 将类名称转换为从0开始计的类别索引\n",
    "    label_number = tf.to_int32(tf.argmax(tf.to_int32(tf.stack([\n",
    "        tf.equal(label, [\"Iris-setosa\"]),\n",
    "        tf.equal(label, [\"Iris-versicolor\"]),\n",
    "        tf.equal(label, [\"Iris-virginica\"])\n",
    "    ])), 0))\n",
    "    \n",
    "    # 最终将所有特征排列在一个矩阵中，然后对该矩阵转置，使其每行对应一个样本，每列对应一种特征\n",
    "    features = tf.transpose(tf.stack([sepal_length, sepal_width, petal_length, petal_width]))\n",
    "    \n",
    "    return features, label_number\n",
    "def train(total_loss):\n",
    "    # 依据计算的总损失训练或调整模型参数\n",
    "    learning_rate = 0.01\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "def evaluate(sess, X, Y):\n",
    "    # 对训练得到的模型进行评估\n",
    "    predicted = tf.cast(tf.arg_max(inference(X), 1), tf.int32)\n",
    "    print sess.run(tf.reduce_mean(tf.cast(tf.equal(predicted, Y), tf.float32)))\n",
    "    \n",
    "# 在一个会话对象中启动数据流图，搭建流程\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X, Y = inputs()\n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 实际的训练迭代次数\n",
    "    training_steps = 1000\n",
    "    for step in range(training_steps):\n",
    "        sess.run([train_op])\n",
    "        # 出于调试和学习的目的，查看损失在训练过程中递减的情况\n",
    "        if step % 10 == 0:\n",
    "            print \"loss: \", sess.run([total_loss])\n",
    "            \n",
    "    evaluate(sess, X, Y)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
